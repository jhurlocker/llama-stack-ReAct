{{- if .Values.servingRuntime.enabled }}
apiVersion: serving.kserve.io/v1alpha1
kind: ServingRuntime
metadata:
  name: llama4-scout
  labels:
    {{- include "llama4-scout.labels" . | nindent 4 }}
  annotations:
    opendatahub.io/apiProtocol: REST
    opendatahub.io/accelerator-name: migrated-gpu
spec:
  supportedModelFormats:
  - name: vLLM
    version: "1"
    autoSelect: true
  - name: huggingface
    version: "1"
    autoSelect: true
  containers:
  - name: kserve-container
    image: {{ .Values.servingRuntime.image | default "quay.io/modh/vllm@sha256:0d55419f3d168fd80868a36ac89815dded9e063937a8409b7edf3529771383f3" }}
    args:
    - --model=/mnt/models
    - --port=8080
    - --max-model-len={{ .Values.model.maxModelLen | default 8192 }}
    - '--served-model-name=llama4-scout'
    - --chat-template=/app/data/template/tool_chat_template_llama4_pythonic.jinja
    - '--enable-auto-tool-choice'
    - '--tensor-parallel-size=4'
    - '--disable-custom-all-reduce'
    - '--enforce-eager'
    - '--tool-call-parser'
    - llama4_pythonic
    env:
    - name: HF_HOME
      value: /tmp/hf_home
    - name: RAY_DISABLE_IMPORT_WARNING
      value: "1"
    - name: RAY_DEDUP_LOGS
      value: "0"
    - name: CUDA_VISIBLE_DEVICES
      value: "0,1,2,3"
    - name: RAY_WORKER_NICENESS
      value: "0"
    - name: RAY_DISABLE_STRICT_VERSION_CHECK
      value: "1"
    {{- range $key, $value := .Values.env }}
    {{- if and (ne $key "HF_HOME") (ne $key "CUDA_VISIBLE_DEVICES") }}
    - name: {{ $key }}
      value: {{ $value | quote }}
    {{- end }}
    {{- end }}
    ports:
    - containerPort: 8080
      name: h2c
      protocol: TCP
    resources:
      {{- toYaml .Values.resources | nindent 6 }}
    volumeMounts:
    - name: shm
      mountPath: /dev/shm
  volumes:
  - name: shm
    emptyDir:
      medium: Memory
      sizeLimit: {{ .Values.servingRuntime.shmSizeLimit | default "1Gi" }}
  {{- with .Values.nodeSelector }}
  nodeSelector:
    {{- toYaml . | nindent 4 }}
  {{- end }}
  {{- with .Values.affinity }}
  affinity:
    {{- toYaml . | nindent 4 }}
  {{- end }}
  {{- with .Values.tolerations }}
  tolerations:
    {{- toYaml . | nindent 4 }}
  {{- end }}
  builtInAdapter:
    serverType: vllm
    runtimeManagementPort: 8080
    memBufferBytes: {{ .Values.servingRuntime.memBufferBytes | default 134217728 }}
    modelLoadingTimeoutMillis: {{ .Values.servingRuntime.modelLoadingTimeoutMillis | default 90000 }}
{{- end }}